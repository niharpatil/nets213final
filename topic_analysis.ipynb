{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('wordbatch2.csv')\n",
    "hit2 = pd.read_csv('hit_2_output.csv')\n",
    "df.head()\n",
    "word_list = []\n",
    "for index, row in df.iterrows():\n",
    "    for ans in range(1,5):\n",
    "        word = row['Answer.topic_'+str(ans)]\n",
    "        if isinstance(word, str):\n",
    "            word_list.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIT2 aggregation general idea\n",
    "\n",
    "-get the categories from HIT1\n",
    "-Give a hueristic of importance to each category to see which questions to ask\n",
    "    -based on number of items in each category\n",
    "    -this shows how much turkers know about each category\n",
    "-Then create questions based on those rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors as word2vec\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "#word_list = ['soccer', 'futbol','football', 'politics','Chelsea','elections','stocks','electronics','India','prime-minister','Champions-league']\n",
    "model = word2vec.KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "unknowns = []\n",
    "knowns = []\n",
    "knames = []\n",
    "#word_list = dic_list\n",
    "for i in range(len(word_list)):\n",
    "    try:\n",
    "        knowns.append(model[word_list[i]])\n",
    "        knames.append(word_list[i])\n",
    "    except:\n",
    "        unknowns.append(word_list[i])\n",
    "    for j in range(len(word_list)):\n",
    "        if word_list[j] not in unknowns:\n",
    "            try:\n",
    "                print (str(word_list[i])+ \", \"+str(word_list[j])+ \": \" + str(model.similarity(word_list[i],word_list[j])))\n",
    "            except:\n",
    "                unknowns.append(word_list[j])\n",
    "\n",
    "dists = []\n",
    "K = range(1,25)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(knowns)\n",
    "    dists.append(km.inertia_)\n",
    "\n",
    "kmeans = KMeans(n_clusters=np.argmin(dists), random_state=0).fit(knowns)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Topic weights from output of HIT 2 and HIT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "total = 0\n",
    "for index, row in hit2.iterrows():\n",
    "    for col in range(49,130):\n",
    "        category = hit2.columns[col]\n",
    "        if row[category] == True:\n",
    "            #point of the last period in the column\n",
    "            p = category.rfind(\".\")\n",
    "            topic = category[p+1:]\n",
    "            num = category[p-1:p]\n",
    "            \n",
    "            add = 2\n",
    "            if row[\"Answer.expertise_\"+num+\".high\"]:\n",
    "                add = 3\n",
    "            elif  row[\"Answer.expertise_\"+num+\".med\"]:\n",
    "                add = 2\n",
    "            elif  row[\"Answer.expertise_\"+num+\".high\"]:\n",
    "                add = 1\n",
    "            total += add\n",
    "            if topic in count:\n",
    "                count[topic] += add\n",
    "            else:\n",
    "                count[topic] = add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in knames:\n",
    "    max_topic = ''\n",
    "    max_cs = -1\n",
    "    for topic in count:\n",
    "        if topic == \"dont_know\" or topic == \"other_sports\" or topic == \"video_games\":\n",
    "            continue\n",
    "        cs = model.similarity(word, topic)\n",
    "        if cs > max_cs:\n",
    "            max_cs = cs\n",
    "            max_topic = topic\n",
    "    count[max_topic] += 6\n",
    "    total += 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in count:\n",
    "    count[topic] /= total\n",
    "    count[topic] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'art': 3.2411288069293094,\n",
       " 'baseball': 1.8943839061190275,\n",
       " 'basketball': 2.112321877619447,\n",
       " 'cooking': 2.8890751606594023,\n",
       " 'dont_know': 1.5982117910030735,\n",
       " 'education': 8.533109807208717,\n",
       " 'finance': 4.235820061469684,\n",
       " 'football': 3.056719754121263,\n",
       " 'gardening': 2.347024308466052,\n",
       " 'hobby': 7.974294495669182,\n",
       " 'literature': 4.498463257893266,\n",
       " 'math': 1.4138027381950267,\n",
       " 'movies': 2.442022911427773,\n",
       " 'music': 4.660519698239732,\n",
       " 'nutrition': 4.3419949706621965,\n",
       " 'other': 10.930427493713328,\n",
       " 'other_sports': 3.3137747974294496,\n",
       " 'parenting': 3.028778988544286,\n",
       " 'pets': 2.905839620005588,\n",
       " 'photography': 1.587035484772283,\n",
       " 'politics': 3.352891869237217,\n",
       " 'religion': 1.7546800782341436,\n",
       " 'science': 3.7999441184688463,\n",
       " 'soccer': 1.7546800782341436,\n",
       " 'technology': 6.543727298127969,\n",
       " 'television': 2.78290025146689,\n",
       " 'video_games': 3.006426376082705}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "K = range(1,30)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(knowns)\n",
    "    dists.append(km.inertia_)\n",
    "\n",
    "kmeans = KMeans(n_clusters=np.argmin(dists), random_state=0).fit(knowns)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Psychology', 0.8638474941253662), ('Biology', 0.78260338306427), ('Sociology', 0.7774052023887634)]\n",
      "[('Gardening', 0.9782292246818542), ('gardening', 0.8355257511138916), ('vegetable_gardening', 0.7094038128852844)]\n",
      "[('Basketball', 0.9838793277740479), ('Volleyball', 0.7359228134155273), ('Softball', 0.6746788024902344)]\n",
      "[('Computers', 0.9329081773757935), ('Computer', 0.7407127618789673), ('computers', 0.7210654616355896)]\n",
      "[('Football', 0.9206256866455078), ('Soccer', 0.759657621383667), ('Sports', 0.7445812821388245)]\n",
      "[('Books', 0.9537973403930664), ('Comics', 0.6984010934829712), ('Bookshop', 0.6527296304702759)]\n",
      "[('quilting', 0.8138535022735596), ('crochet', 0.8109740018844604), ('Crochet', 0.8107221126556396)]\n",
      "[('Dogs', 0.8305302858352661), ('Animals', 0.802953839302063), ('animals', 0.7576248645782471)]\n",
      "[('Art', 0.8011147975921631), ('Poetry', 0.7656776905059814), ('Printmaking', 0.7116436958312988)]\n",
      "[('dol##.net_index###.html_http_dol##.net', 0.721744954586029), ('http_dol##.net_index###.html_http', 0.7194985151290894), ('http_dol##.net_index####.html_http', 0.7171704769134521)]\n",
      "[('Music', 0.8682034611701965), ('music', 0.8157165050506592), ('Guitar', 0.6754887104034424)]\n",
      "[('Math', 0.9079212546348572), ('math', 0.821898877620697), ('mathematics', 0.7514215707778931)]\n",
      "[('Cooking', 0.9479556083679199), ('cooking', 0.8826708197593689), ('cook', 0.690744936466217)]\n",
      "[('basketball', 0.8709017038345337), ('soccer', 0.8153940439224243), ('football', 0.8110343217849731)]\n",
      "[('Photography', 0.927348256111145), ('photography', 0.7259604930877686), ('Photographic', 0.6689215302467346)]\n",
      "[('Hiking', 1.0), ('hiking', 0.7093385457992554), ('Hike', 0.6814872026443481)]\n",
      "[('WHOLE_NEW', 0.8512703776359558), ('GEARING_UP_FOR', 0.8479671478271484), ('PICK_YOUR', 0.8478443622589111)]\n",
      "[('Finance', 0.8225609064102173), ('Banking', 0.6772512197494507), ('Financial_Services', 0.6222540736198425)]\n",
      "[('Parenting', 0.9797844886779785), ('parenting', 0.7445102334022522), ('Mothering', 0.6768010258674622)]\n",
      "[('Baseball', 0.9810267686843872), ('baseball', 0.849311351776123), ('MLB', 0.7304302453994751)]\n",
      "[('Education', 0.8045122027397156), ('Teaching', 0.7802101969718933), ('Educations', 0.6979876756668091)]\n",
      "[('Soccer', 0.9441465139389038), ('Hockey', 0.778718113899231), ('Football', 0.7526614665985107)]\n",
      "[('Investing', 0.8900259733200073), ('investing', 0.7400734424591064), ('Harry_Domash_Online', 0.6529433727264404)]\n",
      "[('Fishing', 0.9451600313186646), ('fishing', 0.7352177500724792), ('Sailing', 0.7158492803573608)]\n",
      "[('Nutrition', 0.8624899387359619), ('Medicine', 0.7380903959274292), ('nutrition', 0.7000079154968262)]\n",
      "[('Reddit', 0.9541704654693604), ('Wordpress', 0.7503008246421814), ('Digg', 0.6925498247146606)]\n",
      "[('Movies', 0.982811450958252), ('Movie', 0.7485084533691406), ('movies', 0.6784780621528625)]\n",
      "[('memorizing_vocabulary', 0.670893669128418), ('grammar_vocabulary', 0.6395058035850525), ('conjugating_verbs', 0.6305262446403503)]\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "top_words = []\n",
    "for c in range(np.argmin(dists)):\n",
    "    cluster_words = []\n",
    "    for i in range(len(knowns)):\n",
    "        if(kmeans.labels_[i] == c):\n",
    "            cluster_words.append(knowns[i])    \n",
    "    top3 = model.most_similar(positive=cluster_words, topn=3)\n",
    "    top_words.append(top3[0])\n",
    "    print(top3)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1481"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Psychology', 0.8638474941253662),\n",
       " ('Gardening', 0.9782292246818542),\n",
       " ('Basketball', 0.9838793277740479),\n",
       " ('Computers', 0.9329081773757935),\n",
       " ('Football', 0.9206256866455078),\n",
       " ('Books', 0.9537973403930664),\n",
       " ('quilting', 0.8138535022735596),\n",
       " ('Dogs', 0.8305302858352661),\n",
       " ('Art', 0.8011147975921631),\n",
       " ('dol##.net_index###.html_http_dol##.net', 0.721744954586029),\n",
       " ('Music', 0.8682034611701965),\n",
       " ('Math', 0.9079212546348572),\n",
       " ('Cooking', 0.9479556083679199),\n",
       " ('basketball', 0.8709017038345337),\n",
       " ('Photography', 0.927348256111145),\n",
       " ('Hiking', 1.0),\n",
       " ('WHOLE_NEW', 0.8512703776359558),\n",
       " ('Finance', 0.8225609064102173),\n",
       " ('Parenting', 0.9797844886779785),\n",
       " ('Baseball', 0.9810267686843872),\n",
       " ('Education', 0.8045122027397156),\n",
       " ('Soccer', 0.9441465139389038),\n",
       " ('Investing', 0.8900259733200073),\n",
       " ('Fishing', 0.9451600313186646),\n",
       " ('Nutrition', 0.8624899387359619),\n",
       " ('Reddit', 0.9541704654693604),\n",
       " ('Movies', 0.982811450958252),\n",
       " ('memorizing_vocabulary', 0.670893669128418)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cor = [0] * np.argmin(dists)\n",
    "avg_cor = [0] * np.argmin(dists)\n",
    "n_clust = [0] * np.argmin(dists)\n",
    "for i in range(len(knowns)):\n",
    "    ilabel = kmeans.labels_[i]\n",
    "    tot_cor[ilabel] += model.similarity(knames[i], top_words[ilabel][0])\n",
    "    n_clust[ilabel] += 1\n",
    "for i in range(np.argmin(dists)):\n",
    "    avg_cor[i] = (top_words[i][0],tot_cor[i] / n_clust[i], n_clust[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First number is correlation, second number is the number in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Psychology', 0.5902997267246246, 25),\n",
       " ('Gardening', 0.8739158287644386, 8),\n",
       " ('Basketball', 0.8944290369749069, 10),\n",
       " ('Computers', 0.6778482715288798, 15),\n",
       " ('Football', 0.7235963066418966, 15),\n",
       " ('Books', 0.7705943385759989, 9),\n",
       " ('quilting', 0.64513512807233, 14),\n",
       " ('Dogs', 0.6069824719115308, 19),\n",
       " ('Art', 0.5185368433594704, 24),\n",
       " ('dol##.net_index###.html_http_dol##.net', 0.22521802884037212, 59),\n",
       " ('Music', 0.5956941715752085, 24),\n",
       " ('Math', 0.6399184749885038, 11),\n",
       " ('Cooking', 0.7989143297076226, 20),\n",
       " ('basketball', 0.6462114139607078, 19),\n",
       " ('Photography', 0.7102544486522675, 15),\n",
       " ('Hiking', 0.9999999403953552, 3),\n",
       " ('WHOLE_NEW', 0.6414718429247538, 9),\n",
       " ('Finance', 0.48592983434597653, 18),\n",
       " ('Parenting', 0.8735541755502875, 11),\n",
       " ('Baseball', 0.8824196265024298, 17),\n",
       " ('Education', 0.4810661762952805, 15),\n",
       " ('Soccer', 0.8205217309296131, 16),\n",
       " ('Investing', 0.7309124916791916, 4),\n",
       " ('Fishing', 0.8161789874235789, 3),\n",
       " ('Nutrition', 0.6005270860411904, 11),\n",
       " ('Reddit', 0.8393574953079224, 3),\n",
       " ('Movies', 0.905191159248352, 5),\n",
       " ('memorizing_vocabulary', 0.3493073118083617, 34)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clust = []\n",
    "rnames = []\n",
    "for i in range(len(knowns)):\n",
    "    if(kmeans.labels_[i] == 10):\n",
    "        random_clust.append(knowns[i])  \n",
    "        rnames.append(knames[i])\n",
    "\n",
    "rdists = []\n",
    "rK = range(1,5)\n",
    "for k in rK:\n",
    "    rkm = KMeans(n_clusters=k).fit(random_clust)\n",
    "    rdists.append(rkm.inertia_)\n",
    "\n",
    "rkmeans = KMeans(n_clusters=np.argmin(rdists), random_state=0).fit(random_clust)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "rtop_words = []\n",
    "for c in range(np.argmin(rdists)):\n",
    "    cluster_words = []\n",
    "    for i in range(len(random_clust)):\n",
    "        if(rkmeans.labels_[i] == c):\n",
    "            cluster_words.append(random_clust[i])    \n",
    "    top3 = model.most_similar(positive=cluster_words, topn=1)\n",
    "    rtop_words.append(top3[0])\n",
    "\n",
    "rtot_cor = [0] * np.argmin(rdists)\n",
    "ravg_cor = [0] * np.argmin(rdists)\n",
    "rn_clust = [0] * np.argmin(rdists)\n",
    "for i in range(len(random_clust)):\n",
    "    ilabel = rkmeans.labels_[i]\n",
    "    rtot_cor[ilabel] += model.similarity(rnames[i], rtop_words[ilabel][0])\n",
    "    rn_clust[ilabel] += 1\n",
    "for i in range(np.argmin(rdists)):\n",
    "    ravg_cor[i] = (rtop_words[i][0],rtot_cor[i] / rn_clust[i], rn_clust[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_c = []\n",
    "for i in range(len(knowns)):\n",
    "    if(kmeans.labels_[i] == 9):\n",
    "        rand_c.append(knames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([rand_c,rand_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame(unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(r'just_unknowns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
